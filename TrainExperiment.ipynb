{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ja_JP'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sys import getsizeof\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "from scipy.stats import skewnorm, norm\n",
    "from scipy.special import comb\n",
    "\n",
    "\n",
    "from RnnNoiseKim import CustomRnnStruct,SettingsDict\n",
    "\n",
    "\n",
    "import pickle\n",
    "import scipy.io\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "from collections import Counter \n",
    "import itertools\n",
    "import locale\n",
    "import datetime\n",
    "# Set the locale to Japanese\n",
    "locale.setlocale(locale.LC_TIME, 'ja_JP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = SettingsDict({\n",
    "    \"PrintSettings\": False,\n",
    "    \"Pips\":20, \"T\":200, \"Tdelay\":0, \"Blocks\":2**12, \"BlockLength\":4, \"stim_on\":50, \"stim_dur\":60, \"stim_delay\":10,\n",
    "    \"BioConstraints\":False,\"Clamping\":True,\n",
    "    \"layerNorm\":False,\n",
    "    \"LR_Scheduler\":\"NoLR\" ,\"factor\":0.5,\"patience\":10,\"min_lr\":0.0001,  \n",
    "    \"Wr_Dropout\":False,\"tauS_Dropout\":False,\"Wout_Dropout\":False,\"bout_Dropout\":False,\"pDropout\":0.1,\n",
    "    \"Delay_Type\":\"Fixed\",\"Delays\":[0,200,400,600], \"DelayProbs\":[0.25, 0.25, 0.25, 0.25],  \n",
    "    \"FitSessions\":10, \"num_epochs\":100,\n",
    "    \"SampleTrain\":\"Uniform\", \"accum_steps\":1, \"batch_size\":2**6, \"Loss\":\"MSE\", \"lr\":0.001, \"betas\":(0.9, 0.999),\"weight_decay\":5e-4,\"Regularization\":\"None\", \"lambda\":0.01,\"LrDips\":1,\"eta_min\":0.1,\"weight\":100, \n",
    "    \"catch_decision_Trian_on\":True,\"TrainCatchTrialOnly\":False,\n",
    "    \"Continual\":True,'Eligible Age':5, 'Replacement_Rate':10e-5, 'DecayRate':0.99,\"EWC\":False,\"lambda_ewc\":1000,\n",
    "    \"max_gradient_norm\":10,\"GradientClipping\":True,\"PrintGradientNorms\":False,\n",
    "    \"Manipulation\":\"None\",\n",
    "    \"SuppressLength\":100, \"DelaySuppressOn\":False, \"StimSuppressOn\":False, \"SuppressCatchOnly\":False, \"EvalCatchTrialOnly\":False,  \n",
    "    \"Eval_Threshold\":0.75, \"Eval_Freq\":1, \"GPU_Eval_Blocks\":20,\"BlockMultiplier\": 5, \n",
    "    \"SampleTest\":\"Uniform\", \"RandCatchTest\":False,\"ProbArrayInput\":[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
    "    \"perf\":1, \"catch_perf\":0.95, \n",
    "    \"InitEvaluate\":False, \"filename\":\"Fit\",\"EpochSaveFreq\":5,\n",
    "    \"Validate\": True,\"ValFreq\":3,\n",
    "    \"TrainSetEval\":False,\n",
    "    \"mu_InternalNoise\":0,\"sigma_InternalNoise\":1,\"mu_ExternalNoise\":0,\"sigma_ExternalNoise\":0.01\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Selected:  cuda\n",
      "\n",
      "\n",
      "Model parameters saved to database.\n",
      "c:\\Users\\cilli\\OneDrive\\Documents\\RIKEN\\CellSubmission\\RNNmodelDB\\sigmoid\\RateRNNstructNUM10.db\n",
      "0.78125\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 500\n",
    "apply_dale = True\n",
    "prop_inh = 0.3\n",
    "prop_som = 0.1\n",
    "prob_rec = 1.0\n",
    "Prop_PUL = 0.14\n",
    "Prop_TRN = 0.06\n",
    "gain = 3.5\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "noise_channels = 10\n",
    "tausRange = [4, 20]\n",
    "Device = \"cuda\"\n",
    "ppc_rate = \"sigmoid\" #'leaky_relu' \n",
    "pul_rate = \"sigmoid\" #'leaky_relu', \"surrogate_generalized_sigmoid\"\n",
    "trn_rate = \"sigmoid\"#'alpha_leaky_relu', \"generalized_sigmoid\", \"sigmoid\", \"surrogate_sigmoid\"\n",
    "\n",
    "NewModel = True\n",
    "SubModelName = \"sigmoid\" # \"generalized_sigmoid\"\n",
    "\n",
    "\n",
    "db_path = None\n",
    "#db_path = r'c:\\\\Users\\\\cilli\\\\OneDrive\\\\Documents\\\\RIKEN\\\\CellSubmission\\\\RNNmodelDB\\\\Test_Sigmoid\\\\RateRNNstructNUM0.db'\n",
    "model0 = CustomRnnStruct(  N, Prop_PUL, Prop_TRN, apply_dale, prop_inh, prop_som, prob_rec, gain, input_size, output_size, noise_channels,tausRange, ppc_rate, pul_rate, trn_rate, Device, NewModel, SubModelName, db_path)\n",
    "print(model0.db_path)\n",
    "\n",
    "# Sample data\n",
    "data =  model0.Wr.detach().cpu().numpy().flatten()  # 1000 random values\n",
    "print(max(data))\n",
    "# Sort the data\n",
    "sorted_data = np.sort(data)\n",
    "\n",
    "# Calculate the cumulative distribution (y-values range from 0 to 1)\n",
    "cumulative_distribution = np.linspace(0, 1, len(sorted_data))\n",
    "\n",
    "# Plot the cumulative distribution\n",
    "plt.plot(sorted_data, cumulative_distribution, label='CDF')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.title('Cumulative Distribution of Random Values')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "plt.hist(data,bins=100);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Delay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Dips:  3\n",
      "4096\n",
      "64\n",
      "64.0\n",
      "Uniform\n",
      "Pure\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\cilli\\\\OneDrive\\\\Documents\\\\RIKEN\\\\CellSubmission\\\\RNNmodelDB\\\\sigmoid\\\\RateRNNstructNUM10.db'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model0.load_data(filename=\"Model4_ReLu\")\n",
    "settings[\"batch_size\"] = 2**6 # [32, 256]\n",
    "settings[\"Blocks\"] = 2**12\n",
    "settings[\"DelayProbs\"] = [0.25, 0.25, 0.25, 0.25]\n",
    "settings[\"num_epochs\"] = 30 # Bigger Bacth Size, more Epochs\n",
    "settings[\"FitSessions\"] = 1\n",
    "settings[\"Tdelay\"] = 0\n",
    "settings[\"Delay_Type\"] = \"Fixed\"\n",
    "\n",
    "settings[\"BioConstraints\"] = False\n",
    "settings[\"Clamping\"] = False\n",
    "\n",
    "settings[\"layerNorm\"] = False\n",
    "\n",
    "settings[\"LR_Scheduler\"] = \"CosineAnnealingLR\" #ReduceLROnPlateau  CosineAnnealingLR\n",
    "settings[\"factor\"] = 0.9\n",
    "settings[\"patience\"] = 10\n",
    "settings[\"min_lr\"] = 0.0001\n",
    "\n",
    "settings[\"betas\"] = (0.9, 0.999) # (0.9, 0.999)\n",
    "settings[\"weight_decay\"] = 5e-4 # 1e-2\n",
    "\n",
    "DipLength = 10\n",
    "WholeDips = settings[\"num_epochs\"]//DipLength\n",
    "\n",
    "settings[\"LrDips\"] = WholeDips + 1 if WholeDips%2 == 0  else WholeDips\n",
    "settings[\"lr\"] = 0.001\n",
    "settings[\"eta_min\"] = 0.1\n",
    "\n",
    "settings[\"Loss\"] = \"MSE\" # \"MSE\" \"MAE\" \"LogCosh\"\n",
    "settings[\"accum_steps\"] = 1\n",
    "settings[\"Regularization\"] = \"None\"\n",
    "settings[\"lambda\"] = 0.01\n",
    "settings[\"weight\"] = 1\n",
    "\n",
    "settings[\"catch_perf\"] = 0.96\n",
    "settings[\"EpochSaveFreq\"] = 5\n",
    "settings[\"SampleTrain\"] = \"Uniform\"\n",
    "settings[\"Continual\"] = False\n",
    "settings[\"EWC\"] = False\n",
    "settings[\"lambda_ewc\"] = 100\n",
    "settings[\"max_gradient_norm\"] = 10\n",
    "settings[\"GradientClipping\"] = True\n",
    "settings[\"PrintGradientNorms\"] = False\n",
    "\n",
    "settings[\"SampleTest\"] = \"Pure\"\n",
    "\n",
    "print(\"LR Dips: \",settings[\"LrDips\"])\n",
    "print(settings[\"Blocks\"])\n",
    "print(settings[\"batch_size\"])\n",
    "print(settings[\"Blocks\"]/settings[\"batch_size\"])\n",
    "print(settings[\"SampleTrain\"])\n",
    "print(settings[\"SampleTest\"])\n",
    "model0.db_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.rate_PPC_Params[\"fmax\"] = 1.0\n",
    "model0.rate_PUL_Params[\"fmax\"] = 1.0\n",
    "model0.rate_TRN_Params[\"fmax\"] = 1.0\n",
    "\n",
    "model0.rate_PPC_Params[\"c\"] = 0.0\n",
    "model0.rate_PUL_Params[\"c\"] = 0.0\n",
    "model0.rate_TRN_Params[\"c\"] = 0.0\n",
    "\n",
    "model0.rate_PPC_Params[\"beta\"] = 1.0\n",
    "model0.rate_PUL_Params[\"beta\"] = 1.0\n",
    "model0.rate_TRN_Params[\"beta\"] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Initial Fit Model-------------------------------\n",
      "Session Progress: |████████████----------------------------| 30.0% Complete\r"
     ]
    }
   ],
   "source": [
    "DiscrimPerform = 0\n",
    "CatchPerform = 0\n",
    "settings[\"Tdelay\"] = 0\n",
    "\n",
    "counter = 0\n",
    "while (DiscrimPerform <= 1 and CatchPerform < 0.95) and counter <= 3:\n",
    "    EvalOutput,BreakFlag = model0.train_model(settings)\n",
    "    DiscrimPerform = EvalOutput[\"eval_perf_discrim_mean\"]\n",
    "    CatchPerform = EvalOutput[\"eval_perf_catch_mean\"]\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Manipulation Occurs\n",
      "\n",
      "\n",
      "2025.05.13 - 16:22   Total Performance: 0.470   Discrimination Performance: 0.477   Catch Performance: 0.450\n",
      "Discrimination Left Performance: 0.000   Discrimination Right Performance: 1.000\n",
      "Catch Left Performance: 0.000   Catch Right Performance: 1.000\n"
     ]
    }
   ],
   "source": [
    "EvalOutput = model0.EvalModel(settings,True,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4994, 0.8933, 0.9668,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5003, 0.7204, 0.9903,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5000, 0.9046, 0.9862,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [0.4999, 0.7019, 0.9525,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5001, 0.9370, 0.9933,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.4996, 0.8060, 0.9890,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[0.4997, 0.2931, 0.5196,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5008, 0.9129, 0.9794,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.4999, 0.9525, 0.9956,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [0.4997, 0.7609, 0.9891,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5004, 0.7095, 0.9260,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.4996, 0.7374, 0.8314,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[0.5001, 0.2543, 0.5697,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5003, 0.6422, 0.9363,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5005, 0.7751, 0.9767,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [0.4999, 0.9165, 0.9476,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.4997, 0.8630, 0.9973,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5006, 0.9458, 0.9588,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5003, 0.7623, 0.9021,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.4996, 0.6764, 0.9780,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5004, 0.7864, 0.9833,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [0.5004, 0.9623, 0.9995,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5008, 0.8646, 0.9897,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5000, 0.7124, 0.9153,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[0.5000, 0.7198, 0.8621,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5002, 0.7554, 0.9555,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5004, 0.9670, 0.9990,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [0.5002, 0.8595, 0.9981,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5002, 0.6625, 0.8999,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5007, 0.8739, 0.9964,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[0.5002, 0.3094, 0.7666,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.4996, 0.8283, 0.9832,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.4996, 0.9084, 0.9775,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [0.4998, 0.8470, 0.9957,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.4995, 0.8724, 0.9720,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.4997, 0.6991, 0.8808,  ..., 1.0000, 1.0000, 1.0000]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvalOutput[\"rEvals\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_utility = 0\n",
    "\n",
    "batch_size = EvalOutput[\"rEvals\"][0].shape[0]\n",
    "N = EvalOutput[\"rEvals\"][0].shape[1]\n",
    "blockSteps = EvalOutput[\"rEvals\"][0].shape[2]\n",
    "NumOfUnitsToReplace = 0\n",
    "\n",
    "rateOutput = torch.randn(batch_size, N, blockSteps,device=\"cpu\",requires_grad=False)\n",
    "age = torch.zeros(N, blockSteps,device=\"cpu\",requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.0940, 4.6086, 4.5191, 3.5635, 4.5456, 5.0570, 3.6971, 4.9953, 4.8066,\n",
       "        4.6765, 5.2273, 3.8878, 4.9955, 4.4322, 4.1080, 5.3517, 5.0645, 4.2974,\n",
       "        4.2020, 3.7920, 4.9319, 4.9654, 4.7812, 4.1951, 3.3766, 4.0426, 4.2203,\n",
       "        5.0217, 4.5647, 4.2231, 4.4935, 3.9418, 4.7941, 4.3346, 4.9922, 4.7940,\n",
       "        4.7502, 5.1808, 3.9239, 3.7440, 5.0506, 4.0381, 5.1980, 4.6247, 4.7823,\n",
       "        4.5971, 4.3026, 3.5447, 5.1217, 3.8210, 5.1482, 4.6707, 4.3095, 4.2567,\n",
       "        5.1791, 5.0560, 3.8005, 3.4979, 4.1794, 3.2938, 4.4191, 4.3484, 4.3970,\n",
       "        4.3643, 3.5127, 5.4244, 3.9287, 4.2528, 3.3540, 4.7896, 4.7107, 4.3825,\n",
       "        3.7336, 5.3824, 4.0631, 4.9464, 4.2328, 4.4482, 5.0168, 4.9439, 4.8507,\n",
       "        4.3556, 3.7717, 5.1873, 4.3150, 4.6655, 5.3454, 5.1120, 5.2782, 4.1878,\n",
       "        3.5831, 4.2271, 4.5020, 5.2907, 4.3456, 3.7822, 3.9193, 5.0758, 5.3677,\n",
       "        4.8655, 3.9987, 3.3683, 4.7471, 3.4768, 5.2534, 4.2390, 4.4874, 4.9744,\n",
       "        4.7109, 4.4124, 4.7141, 4.0531, 4.8198, 5.1186, 5.2978, 4.7206, 5.2823,\n",
       "        4.6298, 4.3881, 3.6154, 5.0595, 5.3047, 4.2983, 4.1371, 5.2493, 4.6626,\n",
       "        4.4557, 4.9675, 4.4725, 3.9101, 3.7072, 4.4418, 4.6559, 4.2240, 5.0835,\n",
       "        4.8750, 4.8466, 4.6111, 5.0997, 5.2581, 4.8276, 4.6281, 4.7781, 3.6815,\n",
       "        5.0507, 4.8135, 4.6636, 4.6023, 4.0812, 4.3854, 4.4209, 4.7132, 5.0113,\n",
       "        5.0495, 4.5005, 5.1894, 3.4165, 4.0121, 4.6916, 5.2319, 3.7858, 5.4408,\n",
       "        3.9137, 4.6135, 4.5602, 4.7902, 3.7963, 3.6239, 4.5350, 3.7835, 4.8661,\n",
       "        5.1474, 3.3919, 4.6073, 4.4941, 4.8338, 4.3388, 4.6465, 4.9620, 3.5535,\n",
       "        4.3790, 5.0924, 4.6740, 3.9726, 4.8654, 4.5186, 5.3835, 3.4472, 3.2540,\n",
       "        4.2754, 4.2666, 4.8674, 4.9118, 4.6873, 5.1953, 4.9625, 4.9052, 3.9625,\n",
       "        5.1121, 3.6945, 4.3451, 3.5501, 4.9972, 4.6627, 4.1539, 4.7344, 3.7059,\n",
       "        4.3513, 3.3046, 4.5288, 4.4406, 5.0449, 3.5291, 5.1068, 4.5121, 3.8739,\n",
       "        4.3453, 3.8281, 4.3179, 4.8294, 4.4274, 4.5422, 4.2974, 5.3256, 3.7144,\n",
       "        4.1017, 3.6130, 4.4203, 4.0562, 3.4696, 4.4423, 4.4301, 4.6447, 4.3639,\n",
       "        5.0333, 4.0043, 4.9687, 4.6187, 4.7331, 4.8319, 4.5415, 4.4851, 4.4785,\n",
       "        4.3501, 3.7107, 4.4540, 3.6133, 3.5981, 4.0759, 3.8823, 4.5781, 3.4737,\n",
       "        4.4063, 5.0149, 4.3369, 4.1526, 5.0214, 4.4638, 4.4642, 4.3785, 4.1790,\n",
       "        4.9106, 5.4207, 3.3129, 5.2689, 4.4837, 4.3566, 5.0431, 4.3418, 5.0382,\n",
       "        4.9296, 3.6606, 4.2556, 5.5805, 4.6327, 3.8701, 3.7548, 4.7137, 3.7257,\n",
       "        4.8696, 4.9031, 4.6195, 5.1515, 3.1412, 3.6659, 4.7204, 5.0792, 4.8670,\n",
       "        3.5567, 4.2372, 4.4939, 4.4969, 4.9489, 4.8435, 5.1067, 4.7469, 5.1568,\n",
       "        3.3211, 4.3274, 5.1319, 4.2496, 3.7315, 5.2183, 4.9494, 4.1531, 4.9090,\n",
       "        5.2484, 4.3668, 4.9016, 3.4790, 4.9638, 5.0255, 3.7161, 4.3254, 4.3136,\n",
       "        4.5656, 4.1353, 4.7450, 4.7589, 5.1748, 4.6529, 4.6191, 4.9820, 4.1999,\n",
       "        4.8893, 3.8310, 3.7723, 4.5013, 4.8721, 4.9941, 3.4521, 4.5342, 4.1335,\n",
       "        4.3566, 3.9570, 4.9972, 5.1177, 3.7744, 4.6717, 4.9848, 4.2984, 4.4677,\n",
       "        5.3738, 4.8904, 4.3455, 4.0077, 4.8569, 5.3379, 4.5828, 5.1169, 4.2050,\n",
       "        3.3045, 4.2547, 4.4582, 3.3024, 4.6507, 4.5021, 4.5829, 3.7006, 4.2178,\n",
       "        4.5427, 3.5866, 4.3624, 3.6170, 4.7610, 4.0999, 3.5610, 4.7612, 4.6807,\n",
       "        4.2612, 5.1650, 3.4931, 3.2582, 4.8587, 4.3932, 4.8163, 5.1327, 4.8078,\n",
       "        4.5559, 5.2352, 4.6735, 4.0848, 4.8530, 5.1891, 3.4666, 5.3516, 4.6190,\n",
       "        4.9063, 4.8460, 4.3134, 5.1963, 3.6219, 4.9760, 4.3114, 4.1174, 3.4663,\n",
       "        3.8401, 4.5871, 4.0052, 5.3000, 4.5147, 3.9107, 4.0863, 3.8242, 4.4637,\n",
       "        4.2138, 4.1444, 3.7970, 4.3410, 4.5662, 3.6598, 3.9015, 3.8483, 4.3594,\n",
       "        4.6079, 3.7417, 4.1912, 4.2470, 4.1994, 4.3128, 3.6332, 4.2022, 3.9071,\n",
       "        4.0981, 4.1632, 3.7143, 4.5228, 4.5119, 4.2753, 4.3929, 4.2981, 4.5174,\n",
       "        4.3706, 4.4245, 4.0946, 3.8915, 4.7775, 3.9786, 3.6222, 4.4764, 4.1581,\n",
       "        4.1968, 4.4060, 3.5791, 3.7385, 4.0187, 4.3528, 4.4605, 3.9412, 3.8319,\n",
       "        4.5207, 4.4809, 4.7464, 4.1746, 3.8622, 3.9059, 3.9857, 4.5387, 3.9168,\n",
       "        4.6082, 3.4957, 3.8966, 4.2087, 4.3691, 4.2645, 4.0371, 4.1589, 3.7563,\n",
       "        4.3422, 4.3889, 1.0982, 0.9656, 1.1449, 1.2713, 1.6502, 1.7335, 1.3551,\n",
       "        1.1321, 1.0532, 1.4281, 1.7401, 1.3457, 1.0899, 1.6444, 1.5809, 0.9503,\n",
       "        1.5786, 1.7588, 1.5329, 1.6458, 1.2223, 1.0115, 0.8950, 1.7125, 1.7120,\n",
       "        0.9598, 1.0079, 0.8850, 1.7633, 0.8217])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continual_on = settings[\"Continual\"]\n",
    "continual_on = True\n",
    "eligible_age =  settings[\"Eligible Age\"]\n",
    "replacement_rate = settings[\"Replacement_Rate\"]\n",
    "decay_rate = settings[\"DecayRate\"]\n",
    "\n",
    "Wr_contrib  = torch.zeros(batch_size,N,device=\"cpu\",requires_grad=False)\n",
    "Tau_contrib = torch.zeros(batch_size,N,device=\"cpu\",requires_grad=False)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Update Age\n",
    "#-------------------------------------------------------------------------\n",
    "age += 1\n",
    "\n",
    "\n",
    "if continual_on == True:\n",
    "\n",
    "\n",
    "    if model0.apply_dale == True:\n",
    "        WrDale = torch.relu(model0.Wr)\n",
    "    else:\n",
    "        WrDale = model0.Wr\n",
    "    WrReal = torch.mul( WrDale, model0.SynapseMask).cpu(); \n",
    "    TauS = model0.tauS.cpu()\n",
    "    TauS = TauS.squeeze() \n",
    " \n",
    "    with torch.no_grad():\n",
    "\n",
    "        #-------------------------------------------------------------------------\n",
    "        # Update Utility\n",
    "        #-------------------------------------------------------------------------\n",
    "\n",
    "        for b in range(0,batch_size):\n",
    "            for t in range(0,blockSteps):\n",
    "                Wr_contrib[b,:] += (1-decay_rate) * torch.multiply(torch.abs(rateOutput[b,:,t]),torch.sum(torch.abs(WrReal),dim = 0)) \n",
    "                Tau_contrib[b,:] +=  (1-decay_rate) * torch.multiply(torch.abs(rateOutput[b,:,t]), torch.abs( TauS ))\n",
    "        \n",
    "        # Average Across the Batches\n",
    "        Wr_contrib_avg  = torch.mean(Wr_contrib, dim=0) \n",
    "        Tau_contrib_avg = torch.mean(Tau_contrib,dim=0)\n",
    "\n",
    "        # Calculate Output Utility \n",
    "        output_utility = decay_rate * output_utility + (1-decay_rate)*Wr_contrib_avg + (1-decay_rate)*Tau_contrib_avg\n",
    "        \n",
    "        #-------------------------------------------------------------------------\n",
    "        # Find eligible units: neligible = number of units with age greater than m\n",
    "        #-------------------------------------------------------------------------\n",
    "        eligible_units = (age > eligible_age).sum()\n",
    "\n",
    "\n",
    "        NumOfUnitsToReplace = NumOfUnitsToReplace + eligible_units*replacement_rate\n",
    "\n",
    "        if NumOfUnitsToReplace > 1:\n",
    "            print(\"Update Neuron\")\n",
    "            min_utility_index = torch.argmin(output_utility)\n",
    "            WrN_init = (np.random.normal(loc=0, scale=1.0, size=N))/np.sqrt(N*prob_rec)*gain\n",
    "            if apply_dale == True:\n",
    "                WrN = np.abs(WrN_init)\n",
    "\n",
    "            tauSN = np.random.uniform(tausRange[0], tausRange[1],1)\n",
    "\n",
    "            model0.tauS[min_utility_index,0] = torch.tensor(tauSN)\n",
    "            model0.Wr[:,min_utility_index] = torch.tensor(WrN)\n",
    "            model0.Wout[0,min_utility_index] = 0\n",
    "\n",
    "            output_utility[min_utility_index] = 0\n",
    "            age[min_utility_index] = 0\n",
    "            NumOfUnitsToReplace -= 1\n",
    "\n",
    "output_utility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_utility:  tensor([250.5053, 228.1875, 223.1633, 175.1978, 223.7045, 253.2513, 182.8485,\n",
      "        250.9584, 236.4771, 230.2903, 255.5215, 194.0678, 246.1915, 222.3718,\n",
      "        204.7078, 262.9134, 253.1528, 212.6225, 207.8427, 190.4100, 243.9197,\n",
      "        245.9459, 236.3611, 209.2178, 167.3214, 200.5384, 209.1674, 250.1466,\n",
      "        225.8350, 208.0958, 223.4698, 194.4453, 237.3162, 215.4185, 247.3642,\n",
      "        238.9588, 232.5802, 257.8306, 193.0713, 185.1614, 248.7165, 198.9930,\n",
      "        255.9633, 231.3917, 236.8535, 226.9196, 210.8564, 173.3725, 253.2331,\n",
      "        190.9597, 254.6710, 230.5508, 214.4438, 209.1517, 252.1843, 251.5552,\n",
      "        186.7272, 173.0112, 206.2427, 163.2654, 219.3584, 213.5883, 218.8666,\n",
      "        217.8497, 173.2043, 266.6379, 194.7566, 211.4868, 165.8429, 237.5303,\n",
      "        234.4647, 215.4884, 186.4170, 262.3401, 202.3897, 245.4491, 207.5974,\n",
      "        218.6643, 247.1325, 246.2166, 241.0668, 216.7561, 184.8829, 256.1494,\n",
      "        214.9648, 232.0830, 261.3807, 252.6202, 261.1371, 205.5322, 178.2942,\n",
      "        208.9132, 222.9810, 263.4261, 215.4233, 185.4478, 194.9975, 255.3253,\n",
      "        265.3279, 245.1240, 197.9578, 168.3814, 237.1990, 172.1759, 261.2148,\n",
      "        210.8895, 221.7153, 242.6463, 230.7596, 218.8542, 233.7495, 201.8166,\n",
      "        238.6098, 251.6424, 262.9825, 233.9339, 260.8223, 228.3546, 215.8337,\n",
      "        177.6093, 253.5728, 260.6145, 211.9638, 206.5255, 261.9634, 232.7203,\n",
      "        219.6880, 246.6455, 221.8961, 191.3913, 183.3193, 218.6911, 231.4624,\n",
      "        206.3329, 251.6219, 240.4963, 242.6889, 225.8999, 250.9943, 258.6636,\n",
      "        239.0266, 232.3657, 236.9992, 185.0501, 250.7245, 240.4443, 229.7308,\n",
      "        225.2597, 202.0834, 215.7976, 220.4178, 230.9595, 245.9573, 250.4291,\n",
      "        220.3647, 259.7047, 168.7720, 196.2664, 232.8705, 256.2942, 188.5166,\n",
      "        270.7052, 191.3591, 229.0163, 224.1719, 238.3472, 189.4751, 181.1718,\n",
      "        226.8742, 185.9283, 238.5263, 255.6173, 168.7206, 228.3686, 223.8008,\n",
      "        237.6536, 218.9170, 228.3481, 243.7876, 176.4831, 217.1558, 253.7832,\n",
      "        228.4899, 198.3347, 238.7115, 225.5998, 268.1721, 170.0127, 160.5353,\n",
      "        214.6542, 209.7102, 242.1256, 243.4753, 232.9777, 254.9039, 245.6656,\n",
      "        241.8773, 195.2559, 251.5294, 183.6337, 213.5239, 176.5060, 249.0401,\n",
      "        231.7037, 205.0117, 234.0203, 184.9871, 214.9857, 163.1598, 223.8983,\n",
      "        216.4332, 248.8678, 174.7545, 252.3737, 222.7535, 189.9793, 216.8141,\n",
      "        192.1727, 215.7211, 237.5378, 218.3996, 224.2888, 212.8444, 263.1559,\n",
      "        184.6733, 204.0095, 179.5145, 220.1934, 198.7760, 172.1454, 220.8823,\n",
      "        220.1600, 227.4017, 216.3472, 252.1320, 199.5168, 248.8861, 229.4571,\n",
      "        235.3206, 241.2314, 225.0656, 221.0222, 223.2604, 215.9138, 180.8704,\n",
      "        221.3152, 177.8167, 177.5334, 201.9074, 194.4482, 226.7696, 171.2763,\n",
      "        217.1429, 248.4095, 213.8477, 207.0078, 249.4115, 217.9982, 218.8268,\n",
      "        217.5365, 207.0521, 244.0175, 270.6099, 165.0186, 261.6360, 221.8564,\n",
      "        213.5524, 249.5404, 214.4521, 245.5872, 244.1886, 183.0799, 212.5349,\n",
      "        273.0420, 229.6849, 190.1566, 184.6039, 233.6481, 183.8346, 240.7899,\n",
      "        242.2022, 227.6544, 256.2252, 155.3581, 181.7983, 233.0041, 250.1335,\n",
      "        240.1649, 175.6031, 206.0982, 219.9649, 221.8174, 242.3536, 238.1356,\n",
      "        256.5889, 233.0956, 256.5421, 166.4930, 211.4788, 254.2109, 209.0903,\n",
      "        183.8225, 256.5276, 245.5245, 204.6219, 245.0615, 257.9965, 214.8019,\n",
      "        244.4855, 170.8732, 244.7094, 246.0818, 184.5542, 214.3509, 213.4804,\n",
      "        226.4375, 205.6801, 235.0155, 235.7703, 254.6294, 228.1165, 228.4077,\n",
      "        247.8709, 208.1277, 242.0497, 189.5099, 185.1406, 222.1585, 244.1083,\n",
      "        247.8594, 172.8071, 225.2113, 206.3633, 214.1318, 196.1135, 248.3623,\n",
      "        251.9775, 187.3274, 231.7955, 244.4165, 211.2030, 222.5232, 266.9597,\n",
      "        245.9191, 216.6183, 198.8541, 238.8227, 264.5079, 228.4192, 254.7143,\n",
      "        206.7581, 164.8424, 211.0879, 221.3727, 161.3102, 231.1022, 220.8458,\n",
      "        224.6490, 182.5379, 207.3770, 227.4013, 178.7268, 218.4244, 179.4635,\n",
      "        237.8850, 205.8253, 174.7010, 232.3310, 234.6079, 210.7309, 254.8665,\n",
      "        173.8585, 160.9183, 238.6449, 215.2370, 238.9705, 253.8051, 234.9458,\n",
      "        227.7359, 256.1714, 231.9568, 201.9888, 240.8395, 258.0017, 168.7423,\n",
      "        262.6614, 228.0547, 241.3867, 239.6569, 212.7429, 257.0259, 179.7503,\n",
      "        246.6418, 211.3295, 202.7774, 170.4713, 190.3255, 228.9868, 199.6756,\n",
      "        259.3739, 222.8763, 194.3367, 202.9115, 188.6548, 220.5809, 209.4804,\n",
      "        205.9901, 188.7622, 213.6364, 229.3586, 180.2648, 194.5139, 187.9043,\n",
      "        214.6637, 229.9643, 184.1423, 207.8734, 211.7063, 208.2991, 215.1787,\n",
      "        180.3602, 208.9278, 196.4006, 200.0046, 205.6834, 184.2644, 222.8822,\n",
      "        224.3405, 214.3072, 215.4244, 212.5895, 222.4951, 216.5217, 217.5880,\n",
      "        204.2135, 191.1579, 233.2169, 198.0350, 178.8653, 223.8568, 207.4691,\n",
      "        206.3678, 221.1311, 174.9559, 186.1478, 199.5268, 219.1863, 217.1918,\n",
      "        196.9260, 190.2020, 219.2536, 221.3278, 234.3223, 208.9477, 190.1483,\n",
      "        193.2537, 198.4383, 226.1491, 193.4551, 227.3082, 173.8956, 194.4334,\n",
      "        207.7418, 215.1436, 210.9920, 199.6095, 207.1590, 184.0235, 216.6095,\n",
      "        216.4731,  54.9836,  48.3539,  57.6422,  63.3096,  82.3712,  86.6372,\n",
      "         67.5326,  55.7188,  52.5816,  70.7008,  85.7599,  67.1649,  53.0884,\n",
      "         82.1296,  78.2426,  46.9406,  77.7316,  86.8209,  75.7678,  80.7948,\n",
      "         60.8844,  50.1842,  44.2221,  84.0833,  84.9170,  47.8165,  49.5324,\n",
      "          1.5960,  87.7636,  90.6449])\n",
      "NumOfUnitsToReplace:  0\n",
      "eligible_units:  0\n",
      "age:  tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "output_utility = 0\n",
    "NumOfUnitsToReplace = 0\n",
    "eligible_units = 0\n",
    "blockSteps = EvalOutput[\"rEvals\"][0].shape[2]\n",
    "rateOutput = torch.randn(batch_size, N, blockSteps,device=\"cpu\",requires_grad=False)\n",
    "age = torch.zeros(N, 1,device=\"cpu\",requires_grad=False)\n",
    "\n",
    "print(\"output_utility: \", output_utility)\n",
    "print(\"NumOfUnitsToReplace: \", NumOfUnitsToReplace)\n",
    "print(\"eligible_units: \", eligible_units)\n",
    "print(\"age: \", age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumOfUnitsToReplace:  tensor(0.4995)\n",
      "eligible_units:  tensor(500)\n",
      "age:  tensor([[35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [35.],\n",
      "        [10.],\n",
      "        [35.],\n",
      "        [35.]])\n"
     ]
    }
   ],
   "source": [
    "continual_on = settings[\"Continual\"]\n",
    "continual_on = True\n",
    "eligible_age =  settings[\"Eligible Age\"]\n",
    "replacement_rate = settings[\"Replacement_Rate\"]\n",
    "decay_rate = settings[\"DecayRate\"]\n",
    "\n",
    "batch_size = rateOutput.shape[0]\n",
    "N = rateOutput.shape[1]\n",
    "blockSteps = rateOutput.shape[2]\n",
    "\n",
    "\n",
    "if continual_on == True:\n",
    "    Wr_contrib  = torch.zeros(batch_size,N,device=\"cpu\",requires_grad=False)\n",
    "    Tau_contrib = torch.zeros(batch_size,N,device=\"cpu\",requires_grad=False)\n",
    "\n",
    "\n",
    "\n",
    "    if model0.apply_dale == True:\n",
    "        WrDale = torch.relu(model0.Wr)\n",
    "    else:\n",
    "        WrDale = model0.Wr\n",
    "    WrReal = torch.mul( WrDale, model0.SynapseMask).cpu(); \n",
    "    TauS = model0.tauS.cpu()\n",
    "    TauS = TauS.squeeze() \n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        #-------------------------------------------------------------------------\n",
    "        # Update Age\n",
    "        #-------------------------------------------------------------------------\n",
    "        \n",
    "        age += 1\n",
    "        #-------------------------------------------------------------------------\n",
    "        # Update Utility\n",
    "        #-------------------------------------------------------------------------\n",
    "\n",
    "        rate_abs = torch.abs(rateOutput)  # [B, N, T]\n",
    "        Wr_magnitude = torch.sum(torch.abs(WrReal), dim=0)  # [N]\n",
    "        Tau_magnitude = torch.abs(TauS)  # [N]\n",
    "\n",
    "        Wr_contrib = (1 - decay_rate) * torch.sum(rate_abs * Wr_magnitude[None, :, None], dim=2)\n",
    "        Tau_contrib = (1 - decay_rate) * torch.sum(rate_abs * Tau_magnitude[None, :, None], dim=2)\n",
    "\n",
    "        \n",
    "        # Average Across the Batches\n",
    "        Wr_contrib_avg  = torch.mean(Wr_contrib, dim=0) \n",
    "        Tau_contrib_avg = torch.mean(Tau_contrib,dim=0)\n",
    "\n",
    "        # Calculate Output Utility \n",
    "        output_utility = decay_rate * output_utility + (1-decay_rate)*Wr_contrib_avg + (1-decay_rate)*Tau_contrib_avg\n",
    "        \n",
    "        #-------------------------------------------------------------------------\n",
    "        # Find eligible units: neligible = number of units with age greater than m\n",
    "        #-------------------------------------------------------------------------\n",
    "        eligible_units = (age > eligible_age).sum()\n",
    "\n",
    "\n",
    "        NumOfUnitsToReplace = NumOfUnitsToReplace + (eligible_units*replacement_rate)\n",
    "\n",
    "        if NumOfUnitsToReplace > 1:\n",
    "\n",
    "            min_utility_index = torch.argmin(output_utility)\n",
    "            WrN_init = (np.random.normal(loc=0, scale=1.0, size=N))/np.sqrt(N*prob_rec)*gain\n",
    "            if apply_dale == True:\n",
    "                WrN = np.abs(WrN_init)\n",
    "\n",
    "            tauSN = np.random.uniform(tausRange[0], tausRange[1],1)\n",
    "\n",
    "            model0.tauS[min_utility_index,0] = torch.tensor(tauSN)\n",
    "            model0.Wr[:,min_utility_index] = torch.tensor(WrN)\n",
    "            model0.Wout[0,min_utility_index] = 0\n",
    "\n",
    "            output_utility[min_utility_index] = 0\n",
    "            age[min_utility_index] = 0\n",
    "            NumOfUnitsToReplace -= 1\n",
    "\n",
    "#print(\"output_utility: \", output_utility)\n",
    "print(\"NumOfUnitsToReplace: \", NumOfUnitsToReplace)\n",
    "print(\"eligible_units: \", eligible_units)\n",
    "print(\"age: \", age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(499)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age > eligible_age\n",
    "(age > eligible_age).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_utility = 0\n",
    "\n",
    "batch_size = EvalOutput[\"rEvals\"][0].shape[0]\n",
    "N = EvalOutput[\"rEvals\"][0].shape[1]\n",
    "blockSteps = EvalOutput[\"rEvals\"][0].shape[2]\n",
    "NumOfUnitsToReplace = 0\n",
    "\n",
    "rateOutput = torch.randn(batch_size, N, blockSteps,device=\"cpu\",requires_grad=False)\n",
    "age = torch.zeros(N, blockSteps,device=\"cpu\",requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinitNeurons(rateOutput, output_utility , age, NumOfUnitsToReplace, settings):\n",
    "\n",
    "    continual_on = settings[\"Continual\"]\n",
    "    eligible_age =  settings[\"Eligible Age\"]\n",
    "    replacement_rate = settings[\"Replacement_Rate\"]\n",
    "    decay_rate = settings[\"DecayRate\"]\n",
    "\n",
    "    batch_size = rateOutput.shape[0]\n",
    "    N = rateOutput.shape[1]\n",
    "    blockSteps = rateOutput.shape[2]\n",
    "\n",
    "    UpdateNeuron = None\n",
    "\n",
    "    if continual_on == True:\n",
    "        Wr_contrib  = torch.zeros(batch_size,N,device=\"cpu\",requires_grad=False)\n",
    "        Tau_contrib = torch.zeros(batch_size,N,device=\"cpu\",requires_grad=False)\n",
    "\n",
    "\n",
    "\n",
    "        if model0.apply_dale == True:\n",
    "            WrDale = torch.relu(model0.Wr)\n",
    "        else:\n",
    "            WrDale = model0.Wr\n",
    "        WrReal = torch.mul( WrDale, model0.SynapseMask).cpu(); \n",
    "        TauS = model0.tauS.cpu()\n",
    "        TauS = TauS.squeeze() \n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            #-------------------------------------------------------------------------\n",
    "            # Update Age\n",
    "            #-------------------------------------------------------------------------\n",
    "            \n",
    "            age += 1\n",
    "            #-------------------------------------------------------------------------\n",
    "            # Update Utility\n",
    "            #-------------------------------------------------------------------------\n",
    "\n",
    "            rate_abs = torch.abs(rateOutput)  # [B, N, T]\n",
    "            Wr_magnitude = torch.sum(torch.abs(WrReal), dim=0)  # [N]\n",
    "            Tau_magnitude = torch.abs(TauS)  # [N]\n",
    "\n",
    "            Wr_contrib = (1 - decay_rate) * torch.sum(rate_abs * Wr_magnitude[None, :, None], dim=2)\n",
    "            Tau_contrib = (1 - decay_rate) * torch.sum(rate_abs * Tau_magnitude[None, :, None], dim=2)\n",
    "\n",
    "            \n",
    "            # Average Across the Batches\n",
    "            Wr_contrib_avg  = torch.mean(Wr_contrib, dim=0) \n",
    "            Tau_contrib_avg = torch.mean(Tau_contrib,dim=0)\n",
    "\n",
    "            # Calculate Output Utility \n",
    "            output_utility = decay_rate * output_utility + (1-decay_rate)*Wr_contrib_avg + (1-decay_rate)*Tau_contrib_avg\n",
    "            \n",
    "            #-------------------------------------------------------------------------\n",
    "            # Find eligible units: neligible = number of units with age greater than m\n",
    "            #-------------------------------------------------------------------------\n",
    "            eligible_units = (age > eligible_age).sum()\n",
    "\n",
    "\n",
    "            NumOfUnitsToReplace = NumOfUnitsToReplace + (eligible_units*replacement_rate)\n",
    "\n",
    "            \n",
    "            if NumOfUnitsToReplace > 1:\n",
    "\n",
    "                min_utility_index = torch.argmin(output_utility)\n",
    "                WrN_init = (np.random.normal(loc=0, scale=1.0, size=N))/np.sqrt(N*prob_rec)*gain\n",
    "                if apply_dale == True:\n",
    "                    WrN = np.abs(WrN_init)\n",
    "\n",
    "                tauSN = np.random.uniform(tausRange[0], tausRange[1],1)\n",
    "\n",
    "                model0.tauS[min_utility_index,0] = torch.tensor(tauSN)\n",
    "                model0.Wr[:,min_utility_index] = torch.tensor(WrN)\n",
    "                model0.Wout[0,min_utility_index] = 0\n",
    "\n",
    "                output_utility[min_utility_index] = 0\n",
    "                age[min_utility_index] = 0\n",
    "                NumOfUnitsToReplace -= 1\n",
    "\n",
    "                UpdateNeuron = min_utility_index\n",
    "\n",
    "    return output_utility , age, NumOfUnitsToReplace, UpdateNeuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reinit_History = []\n",
    "Reinit_History.append(UpdateNeuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to TensorBoard\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 None 1 None 3 2 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Simulate data\n",
    "n = 10\n",
    "steps = np.arange(n)\n",
    "values = np.random.choice([1,2,3,None],size=n,replace=True,p=[0.25,0.25,0.25,0.25])\n",
    "print(values)\n",
    "\n",
    "\n",
    "def plotReinit(self,epoch,Reinit_History):\n",
    "\n",
    "    epochs = np.arange(epoch)\n",
    "    # Create marker-only plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    ax.plot(epochs, Reinit_History, '.')  # 'o' for circular markers, no line\n",
    "    ax.set_title(\"Reinit Neurons\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Neuron\")\n",
    "    ax.set_ylim(bottom=-1,top = self.N + 1)\n",
    "    ax.set_xlim(left=0,right = epoch+1)\n",
    "\n",
    "    # Save to buffer and convert to image\n",
    "    buf = BytesIO()\n",
    "    fig.savefig(buf, format='png', dpi=100, bbox_inches='tight')  # lower DPI\n",
    "    buf.seek(0)\n",
    "    image = PIL.Image.open(buf)\n",
    "    image = np.array(image)\n",
    "\n",
    "\n",
    "    writer.add_image(\"Reinit Neurons\", image, global_step=epoch, dataformats='HWC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_utility:  0\n",
      "NumOfUnitsToReplace:  0\n",
      "eligible_units:  0\n",
      "age:  tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "output_utility = 0\n",
    "NumOfUnitsToReplace = 0\n",
    "eligible_units = 0\n",
    "blockSteps = EvalOutput[\"rEvals\"][0].shape[2]\n",
    "rateOutput = torch.randn(batch_size, N, blockSteps,device=\"cpu\",requires_grad=False)\n",
    "age = torch.zeros(N, 1,device=\"cpu\",requires_grad=False)\n",
    "\n",
    "print(\"output_utility: \", output_utility)\n",
    "print(\"NumOfUnitsToReplace: \", NumOfUnitsToReplace)\n",
    "print(\"eligible_units: \", eligible_units)\n",
    "print(\"age: \", age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "Reinit_History = []\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46\n",
      "[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, tensor(492), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, tensor(492)]\n",
      "NumOfUnitsToReplace tensor(0.0495)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_utility , age, NumOfUnitsToReplace, UpdateNeuron = reinitNeurons(rateOutput, output_utility , age, NumOfUnitsToReplace, settings)\n",
    "Reinit_History.append(UpdateNeuron)\n",
    "epoch +=1\n",
    "print(\"Epoch\", epoch)\n",
    "print(Reinit_History)\n",
    "print(\"NumOfUnitsToReplace\",NumOfUnitsToReplace)\n",
    "#print(\"age\",age)\n",
    "plotReinit(epoch,Reinit_History)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m EvalOutput \u001b[38;5;241m=\u001b[39m \u001b[43mmodel0\u001b[49m\u001b[38;5;241m.\u001b[39mEvalModel(settings,\u001b[38;5;28;01mTrue\u001b[39;00m,[])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model0' is not defined"
     ]
    }
   ],
   "source": [
    "EvalOutput = model0.EvalModel(settings,True,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays = np.arange(0,50,50)\n",
    "\n",
    "RandomDelay = False\n",
    "LastCatchSuccess = 0\n",
    "\n",
    "ParameterResetValue = 6\n",
    "for delay in delays:    \n",
    "\n",
    "    settings[\"Tdelay\"] = delay\n",
    "    DiscrimPerform = 0\n",
    "    CatchPerform = 0\n",
    "    BreakFlag = 0\n",
    "    WhileCounter = 0\n",
    "    while (DiscrimPerform <= 1 and CatchPerform < 0.95): \n",
    "        print(\"------------------------------------\\n\")\n",
    "        print(f\"--------Delay: {delay}-------------\\n\")\n",
    "        print(\"------------------------------------\\n\")\n",
    "\n",
    "        if (WhileCounter >= ParameterResetValue and delay > 0) or (CatchPerform <= 0.2 and delay > 0 and WhileCounter >= 1):\n",
    "            WhileCounter = 0\n",
    "            print(\"-----Reload Model-----\")\n",
    "            model0.reload_rnn_from_db(model0.db_path,LastCatchSuccess)\n",
    "\n",
    "        EvalOutput,BreakFlag = model0.train_model(settings)\n",
    "        DiscrimPerform = EvalOutput[\"eval_perf_discrim_mean\"]\n",
    "        CatchPerform = EvalOutput[\"eval_perf_catch_mean\"]\n",
    "        WhileCounter += 1\n",
    "        print(\"WhileCounter: \", WhileCounter)\n",
    "        BioActivation = [\"leaky\" in x for x in [model0.ppc_rate_String,model0.pul_rate_String,model0.trn_rate_String]]\n",
    "        if BreakFlag == 1:\n",
    "            print(\"--Step--\") \n",
    "            break\n",
    "        if BreakFlag == 2 and all(not x for x in BioActivation):\n",
    "            print(\"-----Reload Model-----\")\n",
    "            model0.reload_rnn_from_db(model0.db_path,LastCatchSuccess)\n",
    "            continue\n",
    "    \n",
    "    DiscrimPerform = 0\n",
    "    CatchPerform = 0\n",
    "    BioActivation = [\"leaky\" in x for x in [model0.ppc_rate_String,model0.pul_rate_String,model0.trn_rate_String]]    \n",
    "    if all(x for x in BioActivation):\n",
    "        model0.resetActivation(\"ALL\",\"relu\")\n",
    "        model0.resetActivation(\"TRN\",\"alpha_relu\")\n",
    "        while (DiscrimPerform <= 1 and CatchPerform < 0.95): \n",
    "            print(\"------------------------------------\\n\")\n",
    "            print(f\"--------relu: Transfer-------------\\n\")\n",
    "            print(\"------------------------------------\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            EvalOutput,BreakFlag = model0.train_model(settings)\n",
    "            DiscrimPerform = EvalOutput[\"eval_perf_discrim_mean\"]\n",
    "            CatchPerform = EvalOutput[\"eval_perf_catch_mean\"]\n",
    "            if BreakFlag:\n",
    "                break\n",
    "    \n",
    "    LastCatchSuccess = model0.get_last_index(model0.db_path, \"id\")\n",
    "\n",
    "if RandomDelay == True:\n",
    "    settings[\"Delay_Type\"] = \"Random\"\n",
    "    DiscrimPerform = 0\n",
    "    CatchPerform = 0\n",
    "    BreakFlag = 0\n",
    "    WhileCounter = 0\n",
    "    while (DiscrimPerform <= 1 and CatchPerform < 0.95): \n",
    "        print(\"------------------------------------\\n\")\n",
    "        print(f\"--------Delay Type: Random-------------\\n\")\n",
    "        print(\"------------------------------------\\n\")\n",
    "        EvalOutput,BreakFlag = model0.train_model(settings)\n",
    "        DiscrimPerform = EvalOutput[\"eval_perf_discrim_mean\"]\n",
    "        CatchPerform = EvalOutput[\"eval_perf_catch_mean\"]\n",
    "        WhileCounter += 1\n",
    "        if (WhileCounter >= ParameterResetValue) or (CatchPerform <= 0.2 and WhileCounter >= 1):\n",
    "            WhileCounter = 0\n",
    "            print(\"-----Reload Model-----\")\n",
    "            model0.reload_rnn_from_db(model0.db_path,LastCatchSuccess)\n",
    "\n",
    "        if BreakFlag == 1:\n",
    "            break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvalOutput = model0.EvalModel(settings,True,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "Neurons = 500\n",
    "Channels = 10\n",
    "\n",
    "Wn = torch.ones((Neurons, Channels), device=\"cpu\") * 2         # (N, C)\n",
    "In = torch.randn((batch_size, Channels, 1), device=\"cpu\")      # (B, C, k)\n",
    "\n",
    "# Use 'n' for neurons, 'c' for channels, 'b' for batch, and 'k' for the dummy last dim\n",
    "Wo = torch.einsum(\"nc,bck->bnk\", Wn, In)  # Result: (B, N, 1)\n",
    "\n",
    "print(Wo.shape)  # torch.Size([2, 500, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings[\"Delay_Type\"] = \"Fixed\"\n",
    "EvalOutput = model0.EvalModel(settings,True,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = r'c:\\\\Users\\\\distr\\\\NeuralModels\\\\RNNmodelDB\\\\Experiments\\\\RateRNNstructNUM39.db'\n",
    "model0.load_rnn_from_db(db_path)\n",
    "settings[\"Delay_Type\"] = \"Random\"\n",
    "settings[\"SampleTest\"] = \"Select\"\n",
    "\n",
    "TotalPerform =list()\n",
    "DiscrimPerform =list()\n",
    "CatchPerform =list()\n",
    "CatchLeftPerform =list()\n",
    "CatchRightPerform =list()\n",
    "\n",
    "settings[\"ProbArrayInput\"] = [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "for i in range(0,10):\n",
    "    EvalOutput = model0.EvalModel(settings,True)\n",
    "    TotalPerform.extend([EvalOutput[\"eval_perf_mean\"]])\n",
    "    DiscrimPerform.extend([EvalOutput[\"eval_perf_discrim_mean\"]])\n",
    "    CatchPerform.extend([EvalOutput[\"eval_perf_catch_mean\"]])\n",
    "    CatchLeftPerform.extend([EvalOutput[\"eval_perf_catch_right_mean\"]])\n",
    "    CatchRightPerform.extend([EvalOutput[\"eval_perf_catch_left_mean\"]])\n",
    "    \n",
    "MeanTotalPerform = np.mean(TotalPerform); print(\"Mean Total Perform: \", MeanTotalPerform)\n",
    "MeanDiscrimPerform = np.mean(DiscrimPerform); print(\"Mean Discrim Perform: \", MeanDiscrimPerform)\n",
    "MeanCatchPerform = np.mean(CatchPerform); print(\"Mean Catch Perform: \", MeanCatchPerform)\n",
    "MeanCatchLeftPerform = np.mean(CatchLeftPerform); print(\"Mean Catch Left Perform: \", MeanCatchLeftPerform)\n",
    "MeanCatchRightPerform = np.mean(CatchRightPerform); print(\"Mean Catch Right Perform: \", MeanCatchRightPerform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0,40000,101)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "delays = [1600, 2200, 2800, 3400, 4000]\n",
    "\n",
    "#delays = [9000, 10000,12000,14000,16000]\n",
    "\n",
    "for d in delays:\n",
    "    print(f\"=========Delay{d}==========\")\n",
    "    settings[\"Tdelay\"] = d\n",
    "    settings[\"Delay_Type\"] = \"Fixed\"\n",
    "    settings[\"SampleTest\"] = \"Pure\"\n",
    "    settings[\"GPU_Eval_Blocks\"] = 10\n",
    "    settings[\"BlockMultiplier\"] =  50\n",
    "\n",
    "    EvalOutput = model0.EvalModel(settings,True)\n",
    "\n",
    "    print(\"Total Perform: \", EvalOutput[\"eval_perf_mean\"])\n",
    "    print(\"Mean Discrim Perform: \", EvalOutput[\"eval_perf_discrim_mean\"])\n",
    "    print(\"Mean Catch Perform: \", EvalOutput[\"eval_perf_catch_mean\"])\n",
    "    print(\"Mean Catch Left Perform: \", EvalOutput[\"eval_perf_catch_right_mean\"])\n",
    "    print(\"Mean Catch Right Perform: \", EvalOutput[\"eval_perf_catch_left_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "25*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings[\"Manipulation\"] = \"SuppressNeurons\"\n",
    "settings[\"SampleTest\"] = \"Pure\"\n",
    "settings[\"DelaySuppressOn\"] = True\n",
    "settings[\"SuppressLength\"] = 100\n",
    "settings[\"Delay_Type\"] = \"Random\"\n",
    "settings[\"Tdelay\"] = 200\n",
    "\n",
    "NeuronsSuppressed = model0.PPCIdx\n",
    "NeuronsSuppressed = model0.PPCIdx_Exh\n",
    "NeuronsSuppressed = model0.PPCIdx_Inh\n",
    "\n",
    "NeuronsSuppressed = model0.PulIdx_Exh\n",
    "NeuronsSuppressed = model0.TrnIdx_Inh\n",
    "NeuronsSuppressed = []\n",
    "\n",
    "#print(type(model0.PulIdx_Exh.tolist()))\n",
    "\n",
    "\n",
    "#SynapseSuppressed = list()\n",
    "\n",
    "#SynapseSuppressed.append(model0.PulIdx_Exh.tolist())\n",
    "#SynapseSuppressed.append( model0.TrnIdx_Inh.tolist())\n",
    "#print(SynapseSuppressed)\n",
    "EvalOutput = model0.EvalModel( settings, True, opto_idx=NeuronsSuppressed, PrintResult=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))  # Width = 10 inches, Height = 6 inches\n",
    "GpuBlock = 1\n",
    "Block = 1\n",
    "plt.plot(EvalOutput[\"uEvals\"][GpuBlock][Block])\n",
    "plt.plot(EvalOutput[\"zEvals\"][GpuBlock][Block])\n",
    "plt.plot(EvalOutput[\"oEvals\"][GpuBlock][Block])\n",
    "plt.legend([\"Stim\",\"Target\",\"Rnn Output\"])\n",
    "plt.axhline(y=0.75, color='grey', linestyle='--')  # Horizontal line at y=10\n",
    "plt.axhline(y=-0.75, color='grey', linestyle='--')  # Horizontal line at y=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wr = model0.Wr\n",
    "PPCIdx = model0.PPCIdx\n",
    "PPCIdx_Exh = model0.PPCIdx_Exh\n",
    "PPCIdx_Inh = model0.PPCIdx_Inh\n",
    "\n",
    "\n",
    "\n",
    "PulIdx_Exh = model0.PulIdx_Exh\n",
    "TrnIdx_Inh = model0.TrnIdx_Inh\n",
    "\n",
    "Gt0_01 = list()\n",
    "Gt0_1 = list()\n",
    "Gt0_2 = list()\n",
    "Wippc2pul = torch.tensor([])\n",
    "for ePpcIdx in PPCIdx_Exh:\n",
    "\n",
    "    Wtemp = Wr[PulIdx_Exh, ePpcIdx].detach().cpu()\n",
    "    Gt0_01.append( Wtemp > 0.01)\n",
    "    Gt0_1.append( Wtemp > 0.1)\n",
    "    Gt0_2.append( Wtemp > 0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#db_path = r\"C:\\Users\\distr\\NeuralModels\\RNNmodelDB\\Experiments\\RateRNNstruct3v7NZwN1NUM13.db\"\n",
    "#db_path = r\"C:\\Users\\distr\\NeuralModels\\RNNmodelDB\\Experiments\\RateRNNstructYsFy6j2HNUM16.db\"\n",
    "#db_path = r\"C:\\Users\\distr\\NeuralModels\\RNNmodelDB\\Experiments\\RateRNNstructvRLQDz5BNUM19.db\"\n",
    "db_path = r\"C:\\\\Users\\\\distr\\\\NeuralModels\\\\RNNmodelDB\\\\Experiments\\\\RateRNNstructomM3Z2ueNUM25.db\"\n",
    "model0.load_rnn_from_db(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wr = model0.Wr\n",
    "SynapseMask = model0.SynapseMask\n",
    "\n",
    "\n",
    "WrDale = torch.relu(Wr)\n",
    "WrReal = torch.mul( WrDale, SynapseMask);\n",
    "\n",
    "PPCIdx = model0.PPCIdx\n",
    "PPCIdx_Exh = model0.PPCIdx_Exh\n",
    "PPCIdx_Inh = model0.PPCIdx_Inh\n",
    "\n",
    "PulIdx_Exh = model0.PulIdx_Exh\n",
    "TrnIdx_Inh = model0.TrnIdx_Inh\n",
    "\n",
    "\n",
    "print(\"PPC Connections\")\n",
    "\n",
    "PPCInh2PUL = torch.tensor([])\n",
    "for i in range(0,len(PPCIdx_Inh)):\n",
    "    Wtemp = WrReal[PulIdx_Exh,PPCIdx_Inh[i]].detach().cpu()\n",
    "    PPCInh2PUL = torch.concatenate( (PPCInh2PUL, Wtemp) )\n",
    "\n",
    "PPCExh2PUL = torch.tensor([])\n",
    "for i in range(0,len(PPCIdx_Exh)):\n",
    "    Wtemp = WrReal[PulIdx_Exh,PPCIdx_Exh[i]].detach().cpu()\n",
    "    PPCExh2PUL = torch.concatenate( (PPCExh2PUL, Wtemp) )\n",
    "\n",
    "PPC2PPC = torch.tensor([])\n",
    "for i in range(0,len(PPCIdx)):\n",
    "    Wtemp = WrReal[PPCIdx,PPCIdx[i]].detach().cpu()\n",
    "    PPC2PPC  = torch.concatenate( (PPC2PPC, Wtemp) )\n",
    "\n",
    "PPCExh2PPCInh = torch.tensor([])\n",
    "for i in range(0,len(PPCIdx_Exh)):\n",
    "    Wtemp = WrReal[PPCIdx_Inh,PPCIdx_Exh[i]].detach().cpu()\n",
    "    PPCExh2PPCInh  = torch.concatenate( (PPCExh2PPCInh, Wtemp) )\n",
    "\n",
    "PPCInh2PPCExh = torch.tensor([])\n",
    "for i in range(0,len(PPCIdx_Inh)):\n",
    "    Wtemp = WrReal[PPCIdx_Exh,PPCIdx_Inh[i]].detach().cpu()\n",
    "    PPCInh2PPCExh   = torch.concatenate( (PPCInh2PPCExh , Wtemp) )\n",
    "\n",
    "PPCExh2PPCExh = torch.tensor([])\n",
    "for i in range(0,len(PPCIdx_Exh)):\n",
    "    Wtemp = WrReal[PPCIdx_Exh,PPCIdx_Exh[i]].detach().cpu()\n",
    "    PPCExh2PPCExh  = torch.concatenate( (PPCExh2PPCExh, Wtemp) )\n",
    "\n",
    "PPCInh2PPCInh = torch.tensor([])\n",
    "for i in range(0,len(PPCIdx_Inh)):\n",
    "    Wtemp = WrReal[PPCIdx_Inh,PPCIdx_Inh[i]].detach().cpu()\n",
    "    PPCInh2PPCInh  = torch.concatenate( (PPCInh2PPCInh, Wtemp) )\n",
    "\n",
    "PPCdata = [PPC2PPC ,PPCExh2PPCExh,PPCInh2PPCInh,PPCExh2PPCInh,PPCInh2PPCExh,PPCInh2PUL,PPCExh2PUL]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(len(PPCdata), 1, figsize=(8, 12), constrained_layout=True)\n",
    "\n",
    "# Determine the global min and max for the x-axis range\n",
    "flattened_PPCdata = torch.cat(PPCdata)\n",
    "global_min = min(flattened_PPCdata )\n",
    "global_max = max(flattened_PPCdata )\n",
    "\n",
    "PPCdataNames = [\"PPC -> PPC\" ,\"PPCExh -> PPCExh\",\"PPCInh -> PPCInh\",\"PPCExh -> PPCInh\",\"PPCInh -> PPCExh\",\"PPCInh -> PUL\",\"PPCExh -> PUL\"]\n",
    "# Plot each histogram\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.hist(PPCdata[i], bins=50, color='blue', alpha=0.7)\n",
    "    ax.set_title(f\"Histogram {i+1}\")\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_xlim(global_min, global_max)  # Set the same x-axis for all histograms\n",
    "    ax.set_title(PPCdataNames[i])\n",
    "\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wr = model0.Wr\n",
    "SynapseMask = model0.SynapseMask\n",
    "\n",
    "\n",
    "WrDale = torch.relu(Wr)\n",
    "WrReal = torch.mul( WrDale, SynapseMask);\n",
    "\n",
    "PPCIdx = model0.PPCIdx\n",
    "PPCIdx_Exh = model0.PPCIdx_Exh\n",
    "PPCIdx_Inh = model0.PPCIdx_Inh\n",
    "\n",
    "PulIdx = model0.PulIdx_Exh\n",
    "TrnIdx = model0.TrnIdx_Inh\n",
    "\n",
    "\n",
    "print(\"PPC Connections\")\n",
    "\n",
    "PPC2PPC = torch.tensor([])\n",
    "for i in range(0,len(PPCIdx)):\n",
    "    Wtemp = SynapseMask[PPCIdx,PPCIdx[i]].detach().cpu()\n",
    "    PPC2PPC  = torch.concatenate( (PPC2PPC, Wtemp) )\n",
    "\n",
    "PPCExh2PPCExh = torch.tensor([])\n",
    "for i in range(0,len(PPCIdx_Exh)):\n",
    "    Wtemp = SynapseMask[PPCIdx_Exh,PPCIdx_Exh[i]].detach().cpu()\n",
    "    PPCExh2PPCExh  = torch.concatenate( (PPCExh2PPCExh, Wtemp) )\n",
    "\n",
    "PPCInh2PPCInh = torch.tensor([])\n",
    "for i in range(0,len(PPCIdx_Inh)):\n",
    "    Wtemp = SynapseMask[PPCIdx_Inh,PPCIdx_Inh[i]].detach().cpu()\n",
    "    PPCInh2PPCInh  = torch.concatenate( (PPCInh2PPCInh, Wtemp) )\n",
    "\n",
    "PPCExh2PPCInh = torch.tensor([])\n",
    "for i in range(0,len(PPCIdx_Exh)):\n",
    "    Wtemp = SynapseMask[PPCIdx_Inh,PPCIdx_Exh[i]].detach().cpu()\n",
    "    PPCExh2PPCInh  = torch.concatenate( (PPCExh2PPCInh, Wtemp) )\n",
    "\n",
    "PPCInh2PPCExh = torch.tensor([])\n",
    "for i in range(0,len(PPCIdx_Inh)):\n",
    "    Wtemp = SynapseMask[PPCIdx_Exh,PPCIdx_Inh[i]].detach().cpu()\n",
    "    PPCInh2PPCExh   = torch.concatenate( (PPCInh2PPCExh , Wtemp) )\n",
    "\n",
    "\n",
    "\n",
    "PPCInh2PUL = torch.tensor([])\n",
    "for i in range(0,len(PPCIdx_Inh)):\n",
    "    Wtemp = SynapseMask[PulIdx,PPCIdx_Inh[i]].detach().cpu()\n",
    "    PPCInh2PUL = torch.concatenate( (PPCInh2PUL, Wtemp) )\n",
    "\n",
    "PPCExh2PUL = torch.tensor([])\n",
    "for i in range(0,len(PPCIdx_Exh)):\n",
    "    Wtemp = SynapseMask[PulIdx,PPCIdx_Exh[i]].detach().cpu()\n",
    "    PPCExh2PUL = torch.concatenate( (PPCExh2PUL, Wtemp) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PPCdata = [PPC2PPC ,PPCExh2PPCExh,PPCInh2PPCInh,PPCExh2PPCInh,PPCInh2PPCExh,PPCInh2PUL,PPCExh2PUL]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(len(PPCdata), 1, figsize=(8, 12), constrained_layout=True)\n",
    "\n",
    "# Determine the global min and max for the x-axis range\n",
    "flattened_PPCdata = torch.cat(PPCdata)\n",
    "global_min = min(flattened_PPCdata )\n",
    "global_max = max(flattened_PPCdata )\n",
    "\n",
    "PPCdataNames = [\"PPC -> PPC\" ,\"PPCExh -> PPCExh\",\"PPCInh -> PPCInh\",\"PPCExh -> PPCInh\",\"PPCInh -> PPCExh\",\"PPCInh -> PUL\",\"PPCExh -> PUL\"]\n",
    "# Plot each histogram\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.hist(PPCdata[i], bins=50, color='blue', alpha=0.7)\n",
    "    ax.set_title(f\"Histogram {i+1}\")\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_xlim(global_min, global_max)  # Set the same x-axis for all histograms\n",
    "    ax.set_title(PPCdataNames[i])\n",
    "\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wr = model0.Wr\n",
    "PPCIdx = model0.PPCIdx\n",
    "PPCIdx_Exh = model0.PPCIdx_Exh\n",
    "PPCIdx_Inh = model0.PPCIdx_Inh\n",
    "\n",
    "PulIdx_Exh = model0.PulIdx_Exh\n",
    "TrnIdx_Inh = model0.TrnIdx_Inh\n",
    "\n",
    "Wippc2pul = torch.tensor([])\n",
    "for iPpcIdx in PPCIdx_Inh:\n",
    "\n",
    "    Wtemp = Wr[PulIdx_Exh, iPpcIdx].detach().cpu()\n",
    "    \n",
    "    Wippc2pul = torch.concatenate([Wippc2pul,Wtemp])\n",
    "\n",
    "filtered_Wippc2pul = Wippc2pul[Wippc2pul != 0]\n",
    "#plt.hist(Wippc2pul,bins=50);\n",
    "plt.hist(filtered_Wippc2pul,bins=50);\n",
    "plt.title(\"PPC Inh to PUL\")\n",
    "\n",
    "Weppc2pul = torch.tensor([])\n",
    "for ePpcIdx in PPCIdx_Exh:\n",
    "\n",
    "    Wtemp = Wr[PulIdx_Exh, ePpcIdx].detach().cpu()\n",
    "    \n",
    "    Weppc2pul = torch.concatenate([Weppc2pul,Wtemp])\n",
    "plt.figure()\n",
    "filtered_Weppc2pul = Weppc2pul[Weppc2pul != 0]\n",
    "#plt.hist(Weppc2pul,bins=50);\n",
    "plt.hist(filtered_Weppc2pul,bins=50);\n",
    "plt.title(\"PPC Exh to PUL\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "SuppressLength = 100\n",
    "DelayLength = 100\n",
    "\n",
    "#if settings[\"DelaySuppressOn\"] == True:\n",
    "#    assert SuppressLength < DelayLength, \"Suppress Length is less than Delay Length\"\n",
    "\n",
    "\n",
    "N = model0.N\n",
    "DelayMax = torch.max(EvalOutput[\"DelayStartEval\"][0]).tolist()\n",
    "print(DelayMax)\n",
    "\n",
    "optoMask_Time = torch.ones(N,N,DelayMax)\n",
    "\n",
    "# Calculate memory usage in bytes\n",
    "memory_bytes = optoMask_Time.numel() * optoMask_Time.element_size()\n",
    "\n",
    "# Convert to kilobytes, megabytes, etc.\n",
    "memory_mb = memory_bytes  / 2**20     # Megabytes\n",
    "print(f\"Memory usage: {memory_mb:.2f} MB\")\n",
    "\n",
    "\n",
    "for di in range(0,EvalOutput[\"DelayStartEval\"][0].size(1) ):\n",
    "    Didx = EvalOutput[\"DelayStartEval\"][0][:,di] -1\n",
    "    print(Didx)\n",
    "    for i in range(0,len(Didx)):\n",
    "        print(Didx[i])\n",
    "        optoMask_Time[:,:,Didx[i]:SuppressLength ] = 0\n",
    "\n",
    "optoMask_Time[:,:,200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wr =  model0.Wr.detach().cpu().numpy() \n",
    "\n",
    "# Compute eigenvalues\n",
    "eigenvalues = np.linalg.eigvals(Wr)\n",
    "\n",
    "# Plot the eigenvalues on a semilogarithmic scale\n",
    "plt.figure()\n",
    "plt.semilogy(np.abs(eigenvalues), 'o')  # Use absolute values to avoid issues with negative eigenvalues\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Eigenvalue (log scale)\")\n",
    "plt.title(\"Eigenvalues of Wr on Semilogarithmic Scale\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "data =  model0.Wr.detach().cpu().numpy().flatten()  # 1000 random values\n",
    "print(max(data))\n",
    "# Sort the data\n",
    "sorted_data = np.sort(data)\n",
    "\n",
    "# Calculate the cumulative distribution (y-values range from 0 to 1)\n",
    "cumulative_distribution = np.linspace(0, 1, len(sorted_data))\n",
    "\n",
    "# Plot the cumulative distribution\n",
    "plt.plot(sorted_data, cumulative_distribution, label='CDF')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.title('Cumulative Distribution of Random Values')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "plt.hist(data,bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "# Assuming these are the model attributes you want to save\n",
    "Wr = model0.Wr.detach().cpu().numpy()  # Convert to NumPy\n",
    "SynapseMask = model0.SynapseMask.detach().cpu().numpy()\n",
    "Wout = model0.Wout.detach().cpu().numpy()\n",
    "tauS = model0.tauS.detach().cpu().numpy()\n",
    "b_out = model0.b_out.detach().cpu().numpy()\n",
    "N = model0.N  # N is already a scalar, no need for conversion\n",
    "\n",
    "# Create a dictionary to store these variables\n",
    "mat_dict = {\n",
    "    'Wr': Wr,\n",
    "    'SynapseMask': SynapseMask,\n",
    "    'Wout': Wout,\n",
    "    'tauS': tauS,\n",
    "    'b_out': b_out,\n",
    "    'N': N\n",
    "}\n",
    "\n",
    "# Save the dictionary to a .mat file\n",
    "scipy.io.savemat('model_parameters_2.mat', mat_dict)\n",
    "\n",
    "print(\"Model parameters saved to model_parameters.mat\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Second Delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RateRnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
